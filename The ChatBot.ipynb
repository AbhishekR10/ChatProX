{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyO9KYLHuZ0ITNm6it9X3AR3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fqYC5n_LuJrp"},"outputs":[],"source":["{\"intents\": [\n","    {\"tag\": \"greeting\",\n","     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n","     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n","    },\n","    {\"tag\": \"goodbye\",\n","     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n","     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n","    },\n","    {\"tag\": \"thanks\",\n","     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n","     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n","    },\n","    {\"tag\": \"about\",\n","     \"patterns\": [\"Who are you?\", \"What are you?\", \"Who you are?\" ],\n","     \"responses\": [\"I.m Joana, your bot assistant\", \"I'm Joana, an Artificial Intelligent bot\"]\n","    },\n","    {\"tag\": \"name\",\n","    \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\"],\n","    \"responses\": [\"You can call me Joana.\", \"I'm Joana!\", \"Just call me as Joana\"]\n","    },\n","    {\"tag\": \"help\",\n","    \"patterns\": [\"Could you help me?\", \"give me a hand please\", \"Can you help?\", \"What can you do for me?\", \"I need a support\", \"I need a help\", \"support me please\"],\n","    \"responses\": [\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\"]\n","    },\n","    {\"tag\": \"createaccount\",\n","    \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \"can you create an account for me\", \"how to open a new account\"],\n","    \"responses\": [\"You can just easily create a new account from our web site\", \"Just go to our web site and follow the guidelines to create a new account\"]\n","    },\n","    {\"tag\": \"complaint\",\n","    \"patterns\": [\"have a complaint\", \"I want to raise a complaint\", \"there is a complaint about a service\"],\n","    \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"]\n","    }\n","]\n","}"]},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"id":"cIvOY6U-ue9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('intents.json') as file:\n","    data = json.load(file)\n","\n","training_sentences = []\n","training_labels = []\n","labels = []\n","responses = []\n","\n","\n","for intent in data['intents']:\n","    for pattern in intent['patterns']:\n","        training_sentences.append(pattern)\n","        training_labels.append(intent['tag'])\n","    responses.append(intent['responses'])\n","\n","    if intent['tag'] not in labels:\n","        labels.append(intent['tag'])\n","\n","num_classes = len(labels)"],"metadata":{"id":"FgrAi5iyyS2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#There is a need to use the label encoder method provided by the Scikit-Learn library in Python\n","label = LabelEncoder()\n","label.fit(training_labels)\n","training_labels = label.transform(training_labels)\n"],"metadata":{"id":"JN_Zy0IZyTag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here is need to vectorize the data using the Tokenization method to create a chatbot with Python and Machine Learning\n","vocab_size = 1000  #This is the maximum number of words to keep, based on word frequency. Only the most common vocab_size words will be kept in the vocabulary\n","embedding_dim = 16  #This is the dimension of the dense embedding. Each word will be represented by a vector of this size.\n","max_len = 20   #This is the maximum length of the sequences after padding. Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n","oov_token = \"<OOV>\"   #This is a special token used to represent out-of-vocabulary (OOV) words.\n","\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n","tokenizer.fit_on_texts(training_sentences)\n","word_index = tokenizer.word_index\n","sequences = tokenizer.texts_to_sequences(training_sentences)\n","padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"],"metadata":{"id":"E3DiyoyMzUeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","#Transform words into dense vectors for neural network input.\n","model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))   #Typically the first layer in a neural network model for text processing.\n","model.add(GlobalAveragePooling1D())\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(16, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()\n","epochs = 500\n","history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"],"metadata":{"id":"aJe-iTcg0Zz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Here training is done of the model,save model so that use this neural network in the future as well\n","model.save(\"chat_Model\")\n","import pickle  #allows to serialize and deserialize Python objects\n","with open('tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)   # saves the tokenizer object to a file named \"tokenizer.pickle\" using pickle. It's a straightforward way to store Python objects for later use, ensuring that the tokenizer can be easily retrieved and reused without needing to retrain it.\n","# to save the fitted label encoder\n","with open('label_encoder.pickle', 'wb') as ecn_file:\n","    pickle.dump(label, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"cMfNgddu1L5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Here to implement a chat function to interact with a real user.When the message from the user will be received, the chatbot will compute the similarity between the sequence of the new text and the training data.\n","import colorama\n","colorama.init()\n","from colorama import Fore, Style, Back\n","\n","import random\n","import pickle\n","\n","with open(\"intents.json\") as file:\n","    data = json.load(file)\n","\n","\n","def chat():\n","    # load trained model\n","    model = keras.models.load_model('chat_model')\n","\n","    # load tokenizer object\n","    with open('tokenizer.pickle', 'rb') as handle:\n","        tokenizer = pickle.load(handle)\n","\n","    # load label encoder object\n","    with open('label_encoder.pickle', 'rb') as enc:\n","        lbl_encoder = pickle.load(enc)\n","\n","    # parameters\n","    max_len = 20\n","\n","    while True:\n","        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n","        inp = input()\n","        if inp.lower() == \"quit\":\n","            break\n","\n","        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n","                                             truncating='post', maxlen=max_len))\n","        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n","\n","        for i in data['intents']:\n","            if i['tag'] == tag:\n","                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n","\n","        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n","\n","print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n","chat()"],"metadata":{"id":"UoMt8f0W3Mdb"},"execution_count":null,"outputs":[]}]}